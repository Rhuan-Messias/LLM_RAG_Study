{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPaFMTnCsRwhiKf8TDqB+fS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh6PTEeC70GM"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token, add_to_git_credential=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from diffusers import AutoPipelineForText2Image\n",
        "import torch\n",
        "\n",
        "pipe = AutoPipelineForText2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16)\n",
        "pipe.to(\"cuda\")\n",
        "display(pipe(prompt=\"a photo of gandalf the white\", num_inference_steps=5, guidance_scale=7.5).images[0])"
      ],
      "metadata": {
        "id": "GWYDhdFo-eAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade datasets==3.6.0"
      ],
      "metadata": {
        "id": "S1mKYkO9H6hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu = !nvidia-smi\n",
        "gpu = '\\n'.join(gpu)\n",
        "\n",
        "if gpu.find('failed') >= 0:\n",
        "  print('No GPU detected')\n",
        "else:\n",
        "  print(gpu)\n",
        "  if gpu.find('Tesla T4') >= 0:\n",
        "    print(\"Connected to a T4\")\n",
        "  else:\n",
        "    print(\"Not connected to a T4\")\n",
        "\n"
      ],
      "metadata": {
        "id": "kd4s4ZgiIq4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import torch\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "from transformers import pipeline\n",
        "from diffusers import DiffusionPipeline\n",
        "from datasets import load_dataset\n",
        "import soundfile as tf\n",
        "from IPython.display import Audio"
      ],
      "metadata": {
        "id": "ayGbwwoYJRRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token, add_to_git_credential=True)"
      ],
      "metadata": {
        "id": "cPxHZfIYJjXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Pipelines from Huggingface\n",
        "my_pipeline = pipeline(task, model=xx, device=xx)\n",
        "if I do not specify a model, it will be taken automatically"
      ],
      "metadata": {
        "id": "D-Kh0vzqMOO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Analysis\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", device='cuda')\n",
        "data = [\"I love you\", \"I hate you\"]\n",
        "sentiment_pipeline(data)"
      ],
      "metadata": {
        "id": "OwtIE-fJLqiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentiment_pipeline(\"I am so happy\")[0]['label'])"
      ],
      "metadata": {
        "id": "Qhvuo-fpNLrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Named Entity Recognition\n",
        "\n",
        "ner = pipeline(\"ner\", device='cuda')\n",
        "result = ner(\"Engineers are learning from Hugginface in Google Colab and LinkedIn\")\n",
        "for entity in result:\n",
        "  print(entity)"
      ],
      "metadata": {
        "id": "PCSFLvTMN8V8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question Answering with Context\n",
        "\n",
        "question=\"Who is Balrog?\"\n",
        "conext=\"Barolg is a demon from Lord of the Rings, written by Tolkien\"\n",
        "\n",
        "answering = pipeline(\"question-answering\", device='cuda')\n",
        "answering(question=question, context=conext)"
      ],
      "metadata": {
        "id": "e58MWdDZQR77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Summarization\n",
        "\n",
        "summarizer = pipeline(\"summarization\", device='cuda')\n",
        "text = '''\n",
        "  The Lord of the Rings is just a part of a whole history, there are 22 books in\n",
        "  total, but only three of them is about Frodo and his adventures. There's the\n",
        "  famous The Hobbit book that also brings the ring tale, but the true adventure\n",
        "  begins several eras ago, which is contexted in the Silmarillion book.\n",
        "'''\n",
        "\n",
        "summarizer(text, max_length=50, min_length=25, do_sample=False)"
      ],
      "metadata": {
        "id": "yaoytBv4Q5dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Translation\n",
        "\n",
        "translator = pipeline('translation_en_to_fr', device=\"cuda\")\n",
        "translator(\"We love Gandalf the gray\")"
      ],
      "metadata": {
        "id": "HBI8H9khRnUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification\n",
        "\n",
        "classifier = pipeline('zero-shot-classification', device=\"cuda\")\n",
        "classifier(\"Gandalf has amazing powers against Balrog fire\", candidate_labels=[\"technology\",\"fantasy\",\"politics\"])"
      ],
      "metadata": {
        "id": "vctkxB0NSCrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Generation\n",
        "\n",
        "generator = pipeline(\"text-generation\", device=\"cuda\")\n",
        "generator(\"This isn't a common hole, this is the hole of a Hobbit, and there is\")"
      ],
      "metadata": {
        "id": "s0LjTj6ZSYRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from diffusers import AutoPipelineForText2Image\n",
        "import torch\n",
        "\n",
        "pipe = AutoPipelineForText2Image.from_pretrained(\n",
        "    \"stabilityai/sdxl-turbo\",\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\")\n",
        "pipe.to(\"cuda\")\n",
        "display(pipe(prompt=\"a photo of Saruman the white\", num_inference_steps=5, guidance_scale=0.0).images[0])"
      ],
      "metadata": {
        "id": "0oyZapjZTH3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Audio Generation\n",
        "\n",
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "import soundfile as sf\n",
        "import torch\n",
        "from IPython.display import Audio\n",
        "import numpy as np\n",
        "\n",
        "converter = pipeline(\"text-to-speech\", \"microsoft/speecht5_tts\", device=\"cuda\")\n",
        "speaker_embedding = torch.zeros(1, 512)\n",
        "speech = converter(\n",
        "    \"Você invocou um modelo quebrado, parabéns.\",\n",
        "    forward_params={\"speaker_embeddings\": speaker_embedding}\n",
        ")\n",
        "speech = converter(\"You shall not pass!\", forward_params={\"speaker_embeddings\": speaker_embedding})\n",
        "\n",
        "Audio(speech['audio'], rate=speech['sampling_rate'])"
      ],
      "metadata": {
        "id": "Wx2h-dxwYaU_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}